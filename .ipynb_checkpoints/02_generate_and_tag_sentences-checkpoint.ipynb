{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCLAIMER: Large part of this code for training new entities based on a pre-trained model, \n",
    "# is taken from Isaac Aderogba under the following link https://deepnote.com/publish/2cc2d19c-c3ac-4321-8853-0bcf2ef565b3\n",
    "# \n",
    "# Statistics Canton Zurich humbly tried to adapt his code to our purposes of training\n",
    "#statistically relevant entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import io, csv\n",
    "import re\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-cb878e40e13f>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['dataset_title'] = df['dataset_title'].str.replace(r\"\\[(.*?)\\]\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 22, 'DATA')]\n",
      "[(16, 29, 'DATA')]\n",
      "[(22, 48, 'DATA')]\n",
      "[(56, 62, 'GRAN'), (9, 47, 'DATA')]\n",
      "[(59, 65, 'GRAN'), (16, 54, 'DATA')]\n",
      "[(9, 21, 'DATA')]\n",
      "[(33, 39, 'GRAN'), (16, 28, 'DATA')]\n",
      "[(22, 37, 'DATA')]\n",
      "[(22, 57, 'DATA')]\n",
      "[(57, 63, 'GRAN'), (9, 37, 'DATA')]\n",
      "[(63, 69, 'GRAN'), (16, 44, 'DATA')]\n",
      "[]\n",
      "[(25, 31, 'GRAN'), (9, 16, 'DATA')]\n",
      "[(34, 41, 'GRAN'), (16, 23, 'DATA')]\n",
      "[(22, 43, 'DATA')]\n",
      "[(22, 42, 'DATA')]\n",
      "[(54, 60, 'GRAN'), (22, 49, 'DATA')]\n",
      "[(9, 41, 'DATA')]\n",
      "[(53, 59, 'GRAN'), (16, 48, 'DATA')]\n",
      "[(9, 30, 'DATA')]\n",
      "[(16, 37, 'DATA')]\n",
      "[(9, 19, 'DATA')]\n",
      "[(32, 44, 'GRAN'), (16, 26, 'DATA')]\n",
      "[(48, 54, 'GRAN'), (9, 39, 'DATA')]\n",
      "[(16, 46, 'DATA')]\n",
      "[(9, 29, 'DATA')]\n",
      "[(16, 36, 'DATA')]\n",
      "[(42, 50, 'GRAN'), (9, 32, 'DATA')]\n",
      "[(45, 51, 'GRAN'), (16, 39, 'DATA')]\n",
      "[(62, 75, 'GRAN')]\n",
      "[]\n",
      "[(9, 53, 'DATA')]\n",
      "[(16, 60, 'DATA')]\n",
      "[(58, 64, 'GRAN'), (9, 52, 'DATA')]\n",
      "[(16, 59, 'DATA')]\n",
      "[(50, 56, 'GRAN'), (22, 44, 'DATA')]\n",
      "[(9, 29, 'DATA')]\n",
      "[(16, 36, 'DATA')]\n",
      "[(53, 61, 'GRAN'), (9, 43, 'DATA')]\n",
      "[(16, 50, 'DATA')]\n",
      "[(9, 31, 'DATA')]\n",
      "[(16, 38, 'DATA')]\n",
      "[(37, 43, 'GRAN'), (9, 19, 'DATA')]\n",
      "[(37, 46, 'GRAN'), (16, 26, 'DATA')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[(77, 83, 'GRAN'), (22, 58, 'DATA')]\n",
      "[(72, 78, 'GRAN'), (9, 49, 'DATA')]\n",
      "[(62, 70, 'GRAN'), (16, 56, 'DATA')]\n",
      "[(9, 29, 'DATA')]\n",
      "[(55, 61, 'GRAN'), (16, 36, 'DATA')]\n",
      "[(59, 67, 'GRAN'), (9, 49, 'DATA')]\n",
      "[(16, 56, 'DATA')]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "nothing to repeat at position 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cb878e40e13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m#2) DATASET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mmatch_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr''\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch_span\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mmatch_span\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatch_span\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    200\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    444\u001b[0m                            not nested and not items))\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    832\u001b[0m             sub_verbose = ((verbose or (add_flags & SRE_FLAG_VERBOSE)) and\n\u001b[1;32m    833\u001b[0m                            not (del_flags & SRE_FLAG_VERBOSE))\n\u001b[0;32m--> 834\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_verbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m                 raise source.error(\"missing ), unterminated subpattern\",\n",
      "\u001b[0;32m/usr/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    444\u001b[0m                            not nested and not items))\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mAT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                 raise source.error(\"nothing to repeat\",\n\u001b[0m\u001b[1;32m    669\u001b[0m                                    source.tell() - here + len(this))\n\u001b[1;32m    670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: nothing to repeat at position 10"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df=pd.read_csv(\"data/datasets_overview.csv\")\n",
    "\n",
    "#one more prepatation\n",
    "df['question_type'] = df['dataset_title'].str.extract(r\"\\[(.*?)\\]\", expand=False)\n",
    "df['question_type'] = np.where(df['question_type']== '%', \"percent\", \"cardinal\")\n",
    "df['dataset_title'] = df['dataset_title'].str.replace(r\"\\[(.*?)\\]\", \"\")\n",
    "#structurize relevant informations such as variables\n",
    "\n",
    "#load content of datasets\n",
    "\n",
    "\n",
    "\n",
    "sentences=pd.read_csv(\"input/question_generator.csv\")\n",
    "out_sentences=[]\n",
    "\n",
    "for i in df['index'].unique():\n",
    "    filename=\"data/\"+str(i)+\".csv\"\n",
    "    with io.open(filename, 'r', encoding=\"latin-1\") as csvfile:\n",
    "        dialect = csv.Sniffer().sniff(csvfile.readline(), [',',';'])\n",
    "        csvfile.seek(0)\n",
    "        mydelimiter=dialect.delimiter\n",
    "    this_data=pd.read_csv(filename,delimiter=dialect.delimiter)\n",
    "    vars=df['var'].loc[df['index'] == i]\n",
    "    dataset_title=df['dataset_title'].loc[df['index']==i].any()\n",
    "    question_type=df['question_type'].loc[df['index']==i].any()\n",
    "    if vars.str.contains(\"INDIKATOR_VALUE\").sum():\n",
    "        main=dataset_title\n",
    "        filter_vars=vars\n",
    "        #print(filter_vars)\n",
    "    else:\n",
    "        continue #temporary so that all variables look alike\n",
    "        print(\"ATTRIBUTING MAIN VARIABLE TO: \",dataset_title)\n",
    "        length_title_string=len(dataset_title.split())\n",
    "        highest_similarity=0\n",
    "        which=None\n",
    "        for var in vars:\n",
    "            temp_string=dataset_title+\" \"+var\n",
    "            #print(temp_string)\n",
    "            doc = nlp(temp_string)\n",
    "            assert len(doc.vector) == len(doc[0].vector)\n",
    "            calc_similarity=doc[:length_title_string].similarity(doc[length_title_string:])\n",
    "            if  calc_similarity> highest_similarity:\n",
    "                highest_similarity=calc_similarity\n",
    "                which=var\n",
    "\n",
    "        print(\"Highest similarity:\",var,highest_similarity)\n",
    "        main=var\n",
    "        vars=vars.tolist()\n",
    "        print(vars)\n",
    "        print(main)\n",
    "        filter_vars=vars.remove(main)\n",
    "    #the following temporary because it is standardized\n",
    "    filter_vars=list(filter_vars)\n",
    "    filter_vars.append(\"\")\n",
    "    try:\n",
    "        filter_vars.remove(\"INDIKATOR_JAHR\")\n",
    "        filter_vars.remove(\"GEBIET_NAME\")\n",
    "        filter_vars.remove(\"BFS_NR\")\n",
    "        filter_vars.remove(\"INDIKATOR_VALUE\")\n",
    "    except:\n",
    "        print(\"variable removing empty\")\n",
    "\n",
    "    for sentence in sentences['question'].loc[sentences['main_type'] == question_type]:\n",
    "        out_entities = []\n",
    "        \n",
    "        sentence=sentence.replace(\"{main}\",main)\n",
    "        sentence=sentence.replace(\"{localitylevel}\",\"\")#at the moment empty\n",
    "        #TODO either one locality, one level, or several localities\n",
    "        random_value=sample([\"one locality\",\"one level\",\"several localities\"],1)[0]\n",
    "        if random_value==\"one locality\":\n",
    "            locality_insert=\"in \"+sample(list(this_data['GEBIET_NAME']),1)[0]\n",
    "        if random_value==\"one level\":\n",
    "            locality_insert=sample([\"f端r den gesamten Kanton\",\"im Kanton Z端rich\",\"auf Bezirksebene\",\n",
    "            \"f端r alle Bezirke\",\"pro Bezirk\",\"auf Gemeindeebene\",\"f端r alle Gemeinden\",\"pro Gemeinde\"],1)[0]\n",
    "        if random_value==\"several localities\":\n",
    "            locality_insert=\"\"\n",
    "            local_loop=sample([1,2,3],1)[0]\n",
    "            for local in range(0,local_loop):\n",
    "                if local!=0 and local!=(local_loop-1):\n",
    "                    locality_insert+=\", \"\n",
    "                if local!=0 and local==(local_loop-1):\n",
    "                    locality_insert+=\" und \"\n",
    "                locality_insert+=sample(list(this_data['GEBIET_NAME']),1)[0]\n",
    "        sentence=sentence.replace(\"{locality}\",locality_insert)\n",
    "        sentence=sentence.replace(\"{yeartime}\",\"\")#TODO no,aktuellste,neuste, value from list, from to year\n",
    "        sentence=sentence.replace(\"{filter}\",sample(list(filter_vars),1)[0])\n",
    "\n",
    "        for mat in re.findall(r'.*?\\[(.*)].*', sentence):\n",
    "            which_part=sample([1,2],1)\n",
    "\n",
    "            if which_part==1:\n",
    "                sentence=sentence.replace(\"[\"+mat+\"]\",mat.partition(\"|\")[0])\n",
    "                #sentence=re.sub(\"[\"+mat+\"]\",mat.partition(\"|\")[0],sentence)\n",
    "            else:\n",
    "                sentence=sentence.replace(\"[\"+mat+\"]\",mat.partition(\"|\")[2])\n",
    "                #sentence=re.sub(\"[\"+mat+\"]\",mat.partition(\"|\")[2],sentence)\n",
    "                \n",
    "        \n",
    "        #now the symbol - has to be deleted as it gives issues\n",
    "        sentence=sentence.replace(\"-\",\"\")\n",
    "        \n",
    "        #### TAGGING\n",
    "\n",
    "        #1) GRAN\n",
    "        match_span = re.search(r'\\bGEMEINDE\\b|\\bGEMEINDEN\\b|\\bGEMEINDEEBENE\\b|\\bBEZIRK\\b|\\bBEZIRKSEBENE\\b|\\bBEZIRKE\\b|\\bKANTON\\b|\\bKANTONSEBENE\\b|\\bREGION\\b', sentence,flags=re.IGNORECASE)\n",
    "        if match_span is not None:\n",
    "            match_span=match_span.span()\n",
    "            out_entities.append((match_span[0], match_span[1], \"GRAN\"))\n",
    "            \n",
    "        #2) DATASET\n",
    "        match_span = re.search(r''+main,sentence,flags=re.IGNORECASE)       \n",
    "        if match_span is not None:\n",
    "            match_span=match_span.span()\n",
    "            out_entities.append((match_span[0], match_span[1], \"DATA\"))\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        out_sentences.append((sentence, {\"entities\": out_entities}))\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "                \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(out_sentences[:10])\n",
    "with open(\"input/tagged_sentences.json\",\"w\") as outfile:\n",
    "    json.dump(out_sentences, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_sentences[1])\n",
    "print(out_sentences[1][0][10])\n",
    "print(out_sentences[1][0][12-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".statbot",
   "language": "python",
   "name": ".statbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
